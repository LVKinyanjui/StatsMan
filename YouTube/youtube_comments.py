# -*- coding: utf-8 -*-
"""Copy of YouTube Data API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hj1MhTvIcx8XP5hiDjQy3FVfrJF2ZfK8

# YouTube Data API
This is one of the two or three APIs that I have been building up to. It would be great to finally be able to collect data from it. It will require the google api python client whose installation is described here https://pypi.org/project/google-api-python-client/
"""

import os
import sys

# Add a directory to the Python search path
sys.path.append('c:/users/user/appdata/local/programs/python/python310/lib/site-packages')

# Import the module from the added directory

from googleapiclient.discovery import build
import pandas as pd

# Get the value of the environment variable
api_key = os.getenv('YOUTUBE_API_KEY')

# Check if the environment variable exists
if api_key is None:
    raise SystemExit("API key not set. Exiting ... ")

youtube = build('youtube', 'v3', developerKey= api_key)

"""## Gathering Inputs"""

video_id =  input("Please Input Video Id here > ")
file_name = input("Input name of output file > ")

for i in range(1, 10):
    try:
        no_results = int(input("Number of comments to gather > "))
        break
    except ValueError:
        print("Please input a valid number")

"""### Pagination Function, 
        function that can loop through several pages of data and return a list.
"""

def get_commentThreads (video_id, max_results):
    
    #Looping over pages
    comments = []
    next_page_token = None
    
    while 1:
        res = youtube.commentThreads().list(part = 'snippet', 
                                            videoId = video_id,
                                            pageToken = next_page_token,
                                            maxResults = max_results
                                           ).execute()
        comments += res['items']
        next_page_token = res.get('nextPageToken')
        
        # If token is none then we have reached the end so break
        if  next_page_token == None:
            break
            
    return comments


""" Function for creating a dataframe from our comments.
"""
def export_csv(comments):
    d = []
    for i in comments:
        d.append(
            {
                'text' : i['snippet']['topLevelComment']['snippet']['textOriginal']
            }
        )
    
    comment_df = pd.DataFrame(d)
    
    """ Exporting to csv"""
    
    comment_df.to_csv(f"./data/{file_name}.csv", index=False)

""" Calling functions
"""
export_csv(get_commentThreads(video_id, no_results))